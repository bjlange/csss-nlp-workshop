{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import nltk\n",
    "import math\n",
    "import collections\n",
    "from textblob import TextBlob\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting data into Python (basic python i/o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csvfile = open(\n",
    "reader = \n",
    "data = []\n",
    "for line in reader:\n",
    "    line[3] = line[3].decode('utf-8')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# getting the number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#taking a look at the first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comment_text = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic python string manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comment_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# strings are like lists of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use a colon for start:end indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# they can be stuck together easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# and split apart\n",
    "comment_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "split_on_questions = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# it's easy to strip whitespace off of them\n",
    "for string in split_on_questions:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# and cast them to one case\n",
    "cleaned = \n",
    "cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# join them back together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# and look for substring inside them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**CHALLENGE: count the number of times the words \"Hilary\" or \"Clinton\" appear in the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for row in data:\n",
    "    comment_text = row[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing TextBlob\n",
    "Like a supercharged string, with lots of NLP niceties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "blob = TextBlob(data[80][-1])\n",
    "blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we can get lists of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lists of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lists of \"tokens\" (punctuation included)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# even parts of speech and noun phrases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarizing/keywording text\n",
    "\n",
    "## How might we find representative words or phrases of a document?\n",
    "\n",
    "###A place to start: which words appear at the highest frequency in this document?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_count = collections.Counter("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge: get overall word counts for all comments combined\n",
    "potential approaches:\n",
    "* glue together all comments into one big blob\n",
    "* get word counts for each comment individually and use Counter's [update function](https://docs.python.org/2/library/collections.html#collections.Counter.update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Problem:** words we use frequently don't make good unique identifiers.\n",
    "\n",
    "One solution: use a list of words we don't want to include\n",
    "\n",
    "### \"Stop Words\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key in word_count.keys():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could continue to add on stopwords as we try to make these keywords better. But it's kind of like playing whack-a-mole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An additional solution to The Problem: add a new term to our \"representative-ness\" measure that accounts for the overall rarity of the word\n",
    "\n",
    "$$\\frac { { n }_{ w } }{ N }  $$\n",
    "\n",
    "where ${ n }_{ w }$ is the number of documents containing word $ w $, and $ N $ is the total number of documents.\n",
    "\n",
    "But we want a potential keyword to have a lower score if it is common in the corpus and a higher score if it is rarer, so we flip it:\n",
    "\n",
    "$$\\frac { N }{ { n }_{ w } }  $$\n",
    "\n",
    "It's also common to take the log of this to reduce the amount of disparity between extremely common and extremely uncommon terms.\n",
    "\n",
    "$$ \\log \\frac { N }{ { n }_{ w } }  $$\n",
    "\n",
    "This is called **IDF**, or Inverse Document Frequency. Let's calculate it for all the words in our comment dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N_documents = float(len(data))\n",
    "word_document_counts = \n",
    "word_idf = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for row in data[1:]:\n",
    "    blob = TextBlob(row[-1].lower())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate IDFs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each word $ w $ in a given document $ D $, we can multiply the term frequency \n",
    "$$\\frac { { D }_{ w } }{ { W }_{ D } } $$ \n",
    "\n",
    "where $ { D }_{ w } $ is the number of occurrences of word $ w $ in document $ D $\n",
    "\n",
    "and $ { W }_{ D } $ is the total number of words in document $ D $\n",
    "\n",
    "with the word's **IDF** that we just calculated to get **TF-IDF** scores, the highest ones being words that likely to be good representatives of that document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comment = data[80][-1]\n",
    "blob = TextBlob(comment.lower())\n",
    "num_words_in_comment = len(blob.words)\n",
    "word_count = blob.word_counts\n",
    "\n",
    "tf_scores = {}\n",
    "for word, count in word_count.iteritems():\n",
    "    if word not in stopwords and len(word) > 2:\n",
    "        tf_scores[word] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_idf = {}\n",
    "for word, tf in tf_scores.iteritems():\n",
    "    tf_idf[word] = \n",
    "\n",
    "sorted(tf_idf.iteritems(), key=lambda k: k[1], reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that TF-IDF can be [tweaked in lots of other ways](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) if you aren't getting good results.\n",
    "\n",
    "It can also be done with \"n-grams\"— phrases that are n words long to capture multi word phrases like \"gay rights\" or \"hillary clinton\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional demonstrations\n",
    "## Boiling down words: stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "print stemmer.stem('political')\n",
    "print stemmer.stem('politics')\n",
    "print stemmer.stem('politician')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seeing words in context: concordance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.text import Text\n",
    "tokens = TextBlob(data[80][-1]).tokens\n",
    "text_object = Text(tokens)\n",
    "text_object.concordance('Hilary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "blob = TextBlob(data[41][-1])\n",
    "blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "blob.sentences[1].sentiment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
